{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iZ5_u81vZys"
      },
      "source": [
        "#Extracción, exploración y analisis datos en netflix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzX9rYUvhKD"
      },
      "source": [
        "Este es un proyecto a modo de autoestudio que tiene como enfasis el proceso ETL o Extract, Transform y Load; para este caso, un dataset que contiene datos de netflix con la cual se hará la manipulación de los mismos. La finalidad es poner en practica mis capacidades y adquierir nuevas destrezas.\n",
        "\n",
        "Realizado por: Luis Felipe Sanchez Sanchez\n",
        "\n",
        "[Dataset](https://www.kaggle.com/datasets/shivamb/netflix-shows?resource=download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWwfX7G1Q2Q"
      },
      "source": [
        "##Librerias y conexiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM7S5_-UwXBa"
      },
      "source": [
        "Importamos librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lRHn0Gz2eZw",
        "outputId": "4ad5ce13-613a-433a-ddb3-536eb8580be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.3.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sqlalchemy in c:\\users\\pipe-\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.38)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pipe-\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pipe-\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#pip install sqlalchemy pymysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gmYY6FKhvAfs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mysql.connector\n",
        "from sqlalchemy import create_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezAdpYUYwl-5",
        "outputId": "7ce52219-f2e6-4b08-ff90-9f62a493230a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Conectamos google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "baKHfNrw1cBI"
      },
      "outputs": [],
      "source": [
        "#Importamos el dataset\n",
        "df = pd.read_csv('netflix_titles.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "uTGx650oxAN4",
        "outputId": "01989eec-06c7-4ebc-99b8-9b3471e41d54"
      },
      "outputs": [],
      "source": [
        "#Creamos la conexión a base de datos de mysql\n",
        "\n",
        "user='root',\n",
        "password='root',\n",
        "host='localhost',\n",
        "database='netflix',\n",
        "port='3306'\n",
        "\n",
        "#creamos el engine de SQLAlchemy\n",
        "engine = create_engine('mysql+pymysql://root:root@localhost:3306/netflix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8807"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Enviamos la info del dataset a mysql\n",
        "df.to_sql(name='netflix', con=engine, if_exists='replace', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iniciamos la sección de análisis en la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Validamos la cantidad maxima de caracteres que tiene la columna show_id\n",
        "print(\"Max: \"+df['show_id'].str.len().max())\n",
        "#Validamos la cantidad minima de caracteres que tiene la columna show_id\n",
        "print(\"Min: \"+df['show_id'].str.len().max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Limpieza de datos, esta se hará mediante MySQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Removemos duplicados desde mysql\n",
        "##primero validamos si hay algún duplicado por el ID\n",
        "select show_id, count(*) \n",
        "from Netflix\n",
        "group by show_id\n",
        "having count(*)>1\n",
        "\n",
        "#Ahora validamos que no hallan titulos repetidos\n",
        "select * \n",
        "from netflix \n",
        "where title in(\n",
        "\tselect title\n",
        "\tfrom netflix\n",
        "\tgroup by title\n",
        "\thaving count(*)>1);\n",
        "#Para ese casi si hay duplicados entonces procederemos a eliminar esas celdas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1448003576.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    SELECT show_id, TRIM(director_name) AS director\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#Separaremos los datos de cast, director y country para un análisis mas sencillo\n",
        "#creamos una columna que divide por coma los directores en caso de haber varios en un film y lo metemos en una nueva tabla\n",
        "CREATE TABLE netflix_directors AS\n",
        "SELECT show_id, TRIM(director_name) AS director\n",
        "FROM netflix\n",
        "JOIN JSON_TABLE(\n",
        "  CONCAT(\n",
        "    '[\"',\n",
        "    REPLACE(REPLACE(IFNULL(director, ''), '\"', ''), ',', '\",\"'),\n",
        "    '\"]'\n",
        "  ),\n",
        "  '$[*]' COLUMNS(director_name VARCHAR(255) PATH '$')\n",
        ") AS jt;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
